{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(333)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and make necessary splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm_train = pd.read_csv(\"dfm_train.csv\")\n",
    "dfm_test = pd.read_csv(\"dfm_test.csv\")\n",
    "y_train = dfm_train[dfm_train.columns[0]]\n",
    "X_train = dfm_train[dfm_train.columns[1:1735]]\n",
    "y_test = dfm_test[dfm_test.columns[0]]\n",
    "X_test = dfm_test[dfm_test.columns[1:1735]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with penalized classification models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9826839826839827\n",
      "Accuracy: 0.7040816326530612\n"
     ]
    }
   ],
   "source": [
    "#build a ridge model\n",
    "\n",
    "ridge = RidgeClassifier(alpha=30).fit(X_train, y_train.ravel())\n",
    "yhat_train_ridge = ridge.predict(X_train)\n",
    "yhat_test_ridge = ridge.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_train, yhat_train_ridge))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, yhat_test_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.961038961038961\n",
      "Accuracy: 0.6836734693877551\n"
     ]
    }
   ],
   "source": [
    "#build an elastic net\n",
    "\n",
    "enet = SGDClassifier(loss='log', penalty='elasticnet', alpha=0.01, l1_ratio=0.5, max_iter = 10000).fit(X_train, y_train.ravel())\n",
    "yhat_train_enet = enet.predict(X_train)\n",
    "yhat_test_enet = enet.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_train, yhat_train_enet))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, yhat_test_enet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all for penalized regression classifiers. Now on to random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Accuracy: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "#number of estimators set to length of X_test (above)\n",
    "clf = RandomForestClassifier(n_estimators=1734)\n",
    "\n",
    "#train the model using the training sets\n",
    "clf.fit(X_train,y_train.values.ravel())\n",
    "# originally had an issue with the above line - https://stackoverflow.com/questions/34165731/a-column-vector-y-was-passed-when-a-1d-array-was-expected helped\n",
    "\n",
    "yhat_train_rf = clf.predict(X_train)\n",
    "yhat_test_rf = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_train, yhat_train_rf))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, yhat_test_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some random forest interpretation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>tax</td>\n",
       "      <td>0.0289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>think</td>\n",
       "      <td>0.0177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>yes</td>\n",
       "      <td>0.0169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>rich</td>\n",
       "      <td>0.0143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>work</td>\n",
       "      <td>0.0135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>district</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>durast</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>ran</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>trial</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>residenti</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1734 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature  importance_score\n",
       "214         tax            0.0289\n",
       "59        think            0.0177\n",
       "190         yes            0.0169\n",
       "105        rich            0.0143\n",
       "242        work            0.0135\n",
       "...         ...               ...\n",
       "1112   district            0.0000\n",
       "1113     durast            0.0000\n",
       "1117        ran            0.0000\n",
       "1119      trial            0.0000\n",
       "1733  residenti            0.0000\n",
       "\n",
       "[1734 rows x 2 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = []\n",
    "scores = []\n",
    "for name, score in zip(X_train.columns,clf.feature_importances_):\n",
    "    names.append(name)\n",
    "    scores.append(np.round(score,4))\n",
    "    \n",
    "score_df = pd.DataFrame({'feature':names,'importance_score':scores})\n",
    "\n",
    "score_df.sort_values('importance_score',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 93.93939393939394\n",
      "Test set accuracy: 70.40816326530613\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(X_train,y_train)\n",
    "yhat_train_NB = Naive.predict(X_train)\n",
    "print(\"Training set accuracy:\", accuracy_score(yhat_train_NB, y_train)*100)\n",
    "yhat_test_NB = Naive.predict(X_test)\n",
    "print(\"Test set accuracy:\", accuracy_score(yhat_test_NB, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 99.13419913419914\n",
      "Test set accuracy: 71.42857142857143\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "SVM = svm.SVC(C=1.7)\n",
    "SVM.fit(X_train,y_train)\n",
    "yhat_train_SVM = SVM.predict(X_train)\n",
    "print(\"Training set accuracy:\",accuracy_score(yhat_train_SVM, y_train)*100)\n",
    "yhat_test_SVM = SVM.predict(X_test)\n",
    "print(\"Test set accuracy:\", accuracy_score(yhat_test_SVM, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They do OK. Try some ensemble techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_clf 0.70408\n",
      "svm_clf 0.69388\n",
      "knn_clf 0.63265\n",
      "nb_clf 0.70408\n",
      "voting_clf 0.7551\n"
     ]
    }
   ],
   "source": [
    "# Voting ensemble\n",
    "np.random.seed(333)\n",
    "rf_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "knn_clf = KNeighborsClassifier()\n",
    "nb_clf = naive_bayes.MultinomialNB()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "                [('rf',rf_clf),\n",
    "                ('svm',svm_clf),\n",
    "                 ('nb', nb_clf),\n",
    "                ('knn',knn_clf)],\n",
    "                voting = \"hard\")\n",
    "\n",
    "voting_clf.fit(X_train,y_train)\n",
    "\n",
    "for name,clf in ([\"rf_clf\",rf_clf],\n",
    "                 [\"svm_clf\",svm_clf],[\"knn_clf\",knn_clf], [\"nb_clf\", nb_clf],\n",
    "                 [\"voting_clf\",voting_clf]):\n",
    "    # fit the model\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    # predict\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # get acc\n",
    "    acc = sum(y_test == y_pred)/len(y_pred)\n",
    "    \n",
    "    print(name, np.round(acc,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The voting classifier can get north of 70% accuracy. Try bagging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 99.13419913419914\n",
      "Test set accuracy: 70.40816326530613\n"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(SVC(),\n",
    "                            n_estimators = 5000,\n",
    "                            max_samples = 230,\n",
    "                            bootstrap = True\n",
    "                           )\n",
    "bag_clf.fit(X_train,y_train)\n",
    "yhat_train_bag = bag_clf.predict(X_train)\n",
    "print(\"Training set accuracy:\", accuracy_score(yhat_train_bag, y_train)*100)\n",
    "yhat_test_bag = bag_clf.predict(X_test)\n",
    "print(\"Test set accuracy:\", accuracy_score(yhat_test_bag, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try boosting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 100.0\n",
      "Training set accuracy: 70.40816326530613\n"
     ]
    }
   ],
   "source": [
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                n_estimators = 1000,\n",
    "                algorithm=\"SAMME.R\",\n",
    "                learning_rate = 0.5\n",
    "            )\n",
    "ada_clf.fit(X_train, y_train)\n",
    "yhat_train_ada_clf = ada_clf.predict(X_train)\n",
    "print(\"Training set accuracy:\", accuracy_score(yhat_train_ada_clf, y_train)*100)\n",
    "yhat_test_ada_clf = ada_clf.predict(X_test)\n",
    "print(\"Test set accuracy:\", accuracy_score(yhat_test_ada_clf, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The voting classifier might work the best, but the random forest classifier doesn't do much worse, so it might be best to work with it because of the interpretability tradeoffs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 100.0\n",
      "Test set accuracy: 74.48979591836735\n"
     ]
    }
   ],
   "source": [
    "forest_clf = RandomForestClassifier(n_estimators=5000, max_features=1734, max_samples=230, random_state=333)\n",
    "forest_clf.fit(X_train,y_train)\n",
    "yhat_train_forest_clf = forest_clf.predict(X_train)\n",
    "print(\"Training set accuracy:\", accuracy_score(yhat_train_forest_clf, y_train)*100)\n",
    "yhat_test_forest_clf = forest_clf.predict(X_test)\n",
    "print(\"Test set accuracy:\", accuracy_score(yhat_test_forest_clf, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
