{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(333)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and make necessary splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm_train = pd.read_csv(\"dfm_train.csv\")\n",
    "dfm_test = pd.read_csv(\"dfm_test.csv\")\n",
    "y_train = dfm_train[dfm_train.columns[0]]\n",
    "X_train = dfm_train[dfm_train.columns[1:1735]]\n",
    "y_test = dfm_test[dfm_test.columns[0]]\n",
    "X_test = dfm_test[dfm_test.columns[1:1735]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with penalized classification models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matt\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "C:\\Users\\Matt\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "C:\\Users\\Matt\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "C:\\Users\\Matt\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "C:\\Users\\Matt\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                             max_iter=None, normalize=False, random_state=None,\n",
       "                             solver='auto', tol=0.001),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'alpha': [1e-15, 1e-10, 1e-08, 0.0001, 0.001, 0.01, 1,\n",
       "                                   5, 10, 20, 30, 40, 50]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build a ridge model\n",
    "\n",
    "ridge = Ridge()\n",
    "\n",
    "parameters = {\"alpha\": [1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20, 30, 40, 50]}\n",
    "\n",
    "ridge_regressor = GridSearchCV(ridge, parameters, scoring = \"neg_mean_squared_error\", cv = 5)\n",
    "\n",
    "ridge_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 30}\n"
     ]
    }
   ],
   "source": [
    "# what's the best model? \n",
    "print(ridge_regressor.best_params_) # alpha = 30 is best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033782</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.004796</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>1e-15</td>\n",
       "      <td>{'alpha': 1e-15}</td>\n",
       "      <td>-0.642680</td>\n",
       "      <td>-0.443169</td>\n",
       "      <td>-0.545957</td>\n",
       "      <td>-0.664898</td>\n",
       "      <td>-0.634874</td>\n",
       "      <td>-0.586316</td>\n",
       "      <td>0.082255</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023787</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>{'alpha': 1e-10}</td>\n",
       "      <td>-0.642680</td>\n",
       "      <td>-0.443169</td>\n",
       "      <td>-0.545957</td>\n",
       "      <td>-0.664898</td>\n",
       "      <td>-0.634874</td>\n",
       "      <td>-0.586316</td>\n",
       "      <td>0.082255</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.022788</td>\n",
       "      <td>0.002560</td>\n",
       "      <td>0.005196</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>{'alpha': 1e-08}</td>\n",
       "      <td>-0.642680</td>\n",
       "      <td>-0.443169</td>\n",
       "      <td>-0.545957</td>\n",
       "      <td>-0.664898</td>\n",
       "      <td>-0.634874</td>\n",
       "      <td>-0.586316</td>\n",
       "      <td>0.082255</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020390</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.004797</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'alpha': 0.0001}</td>\n",
       "      <td>-0.642439</td>\n",
       "      <td>-0.443074</td>\n",
       "      <td>-0.545802</td>\n",
       "      <td>-0.664463</td>\n",
       "      <td>-0.634605</td>\n",
       "      <td>-0.586076</td>\n",
       "      <td>0.082156</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020190</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.004396</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>-0.640295</td>\n",
       "      <td>-0.442215</td>\n",
       "      <td>-0.544410</td>\n",
       "      <td>-0.660589</td>\n",
       "      <td>-0.632211</td>\n",
       "      <td>-0.583944</td>\n",
       "      <td>0.081277</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.019789</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>-0.620832</td>\n",
       "      <td>-0.434013</td>\n",
       "      <td>-0.531547</td>\n",
       "      <td>-0.625741</td>\n",
       "      <td>-0.610849</td>\n",
       "      <td>-0.564596</td>\n",
       "      <td>0.073736</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.017990</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.004197</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>-0.284432</td>\n",
       "      <td>-0.248211</td>\n",
       "      <td>-0.302656</td>\n",
       "      <td>-0.235614</td>\n",
       "      <td>-0.319058</td>\n",
       "      <td>-0.277994</td>\n",
       "      <td>0.031683</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.018990</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.004396</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>5</td>\n",
       "      <td>{'alpha': 5}</td>\n",
       "      <td>-0.205778</td>\n",
       "      <td>-0.205458</td>\n",
       "      <td>-0.239625</td>\n",
       "      <td>-0.181303</td>\n",
       "      <td>-0.230097</td>\n",
       "      <td>-0.212452</td>\n",
       "      <td>0.020559</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.022388</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>0.005395</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "      <td>-0.189070</td>\n",
       "      <td>-0.202366</td>\n",
       "      <td>-0.219679</td>\n",
       "      <td>-0.170546</td>\n",
       "      <td>-0.213000</td>\n",
       "      <td>-0.198932</td>\n",
       "      <td>0.017568</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.024986</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.007195</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>20</td>\n",
       "      <td>{'alpha': 20}</td>\n",
       "      <td>-0.180818</td>\n",
       "      <td>-0.204715</td>\n",
       "      <td>-0.205640</td>\n",
       "      <td>-0.167917</td>\n",
       "      <td>-0.206427</td>\n",
       "      <td>-0.193103</td>\n",
       "      <td>0.015842</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.024786</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.005997</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>30</td>\n",
       "      <td>{'alpha': 30}</td>\n",
       "      <td>-0.179905</td>\n",
       "      <td>-0.207436</td>\n",
       "      <td>-0.201139</td>\n",
       "      <td>-0.170463</td>\n",
       "      <td>-0.206543</td>\n",
       "      <td>-0.193097</td>\n",
       "      <td>0.015082</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.024986</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.006396</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>40</td>\n",
       "      <td>{'alpha': 40}</td>\n",
       "      <td>-0.180947</td>\n",
       "      <td>-0.209628</td>\n",
       "      <td>-0.199772</td>\n",
       "      <td>-0.174070</td>\n",
       "      <td>-0.208127</td>\n",
       "      <td>-0.194509</td>\n",
       "      <td>0.014446</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.023986</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.005796</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>50</td>\n",
       "      <td>{'alpha': 50}</td>\n",
       "      <td>-0.182641</td>\n",
       "      <td>-0.211385</td>\n",
       "      <td>-0.199738</td>\n",
       "      <td>-0.177827</td>\n",
       "      <td>-0.210086</td>\n",
       "      <td>-0.196335</td>\n",
       "      <td>0.013836</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.033782      0.001600         0.004796        0.000745       1e-15   \n",
       "1        0.023787      0.003308         0.005596        0.001200       1e-10   \n",
       "2        0.022788      0.002560         0.005196        0.000979       1e-08   \n",
       "3        0.020390      0.001854         0.004797        0.000749      0.0001   \n",
       "4        0.020190      0.001166         0.004396        0.000800       0.001   \n",
       "5        0.019789      0.002226         0.004596        0.000799        0.01   \n",
       "6        0.017990      0.000632         0.004197        0.000400           1   \n",
       "7        0.018990      0.002529         0.004396        0.000491           5   \n",
       "8        0.022388      0.002332         0.005395        0.000800          10   \n",
       "9        0.024986      0.001414         0.007195        0.000747          20   \n",
       "10       0.024786      0.002039         0.005997        0.000001          30   \n",
       "11       0.024986      0.001787         0.006396        0.000801          40   \n",
       "12       0.023986      0.002896         0.005796        0.000979          50   \n",
       "\n",
       "               params  split0_test_score  split1_test_score  \\\n",
       "0    {'alpha': 1e-15}          -0.642680          -0.443169   \n",
       "1    {'alpha': 1e-10}          -0.642680          -0.443169   \n",
       "2    {'alpha': 1e-08}          -0.642680          -0.443169   \n",
       "3   {'alpha': 0.0001}          -0.642439          -0.443074   \n",
       "4    {'alpha': 0.001}          -0.640295          -0.442215   \n",
       "5     {'alpha': 0.01}          -0.620832          -0.434013   \n",
       "6        {'alpha': 1}          -0.284432          -0.248211   \n",
       "7        {'alpha': 5}          -0.205778          -0.205458   \n",
       "8       {'alpha': 10}          -0.189070          -0.202366   \n",
       "9       {'alpha': 20}          -0.180818          -0.204715   \n",
       "10      {'alpha': 30}          -0.179905          -0.207436   \n",
       "11      {'alpha': 40}          -0.180947          -0.209628   \n",
       "12      {'alpha': 50}          -0.182641          -0.211385   \n",
       "\n",
       "    split2_test_score  split3_test_score  split4_test_score  mean_test_score  \\\n",
       "0           -0.545957          -0.664898          -0.634874        -0.586316   \n",
       "1           -0.545957          -0.664898          -0.634874        -0.586316   \n",
       "2           -0.545957          -0.664898          -0.634874        -0.586316   \n",
       "3           -0.545802          -0.664463          -0.634605        -0.586076   \n",
       "4           -0.544410          -0.660589          -0.632211        -0.583944   \n",
       "5           -0.531547          -0.625741          -0.610849        -0.564596   \n",
       "6           -0.302656          -0.235614          -0.319058        -0.277994   \n",
       "7           -0.239625          -0.181303          -0.230097        -0.212452   \n",
       "8           -0.219679          -0.170546          -0.213000        -0.198932   \n",
       "9           -0.205640          -0.167917          -0.206427        -0.193103   \n",
       "10          -0.201139          -0.170463          -0.206543        -0.193097   \n",
       "11          -0.199772          -0.174070          -0.208127        -0.194509   \n",
       "12          -0.199738          -0.177827          -0.210086        -0.196335   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.082255               13  \n",
       "1         0.082255               12  \n",
       "2         0.082255               11  \n",
       "3         0.082156               10  \n",
       "4         0.081277                9  \n",
       "5         0.073736                8  \n",
       "6         0.031683                7  \n",
       "7         0.020559                6  \n",
       "8         0.017568                5  \n",
       "9         0.015842                2  \n",
       "10        0.015082                1  \n",
       "11        0.014446                3  \n",
       "12        0.013836                4  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the best parameter using mean squared error \n",
    "pd.DataFrame.from_dict(ridge_regressor.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2675444313918127\n",
      "0.7069524631759821\n",
      "0.4427620409556435\n",
      "0.20759633331345495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20759633331345498"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the new model to predict\n",
    "best_ridge = ridge_regressor.best_estimator_\n",
    "\n",
    "#train set\n",
    "yhat_train_ridge = best_ridge.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train,yhat_train_ridge))) # RMSE for training is .239\n",
    "print(r2_score(y_train, yhat_train_ridge)) # R squared is 76.5 percent\n",
    "\n",
    "#test set\n",
    "yhat_test_ridge = best_ridge.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test, yhat_test_ridge))) # RMSE for test data is .448\n",
    "print(r2_score(y_test, yhat_test_ridge)) # R squared is 18.7 percent yikes\n",
    "\n",
    "# accuracy score (same as R2)\n",
    "best_ridge.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                             max_iter=1000, normalize=False, positive=False,\n",
       "                             precompute=False, random_state=None,\n",
       "                             selection='cyclic', tol=0.0001, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'alpha': [1e-15, 1e-10, 1e-08, 0.0001, 0.001, 0.01, 1,\n",
       "                                   5, 10, 20, 30, 40, 50],\n",
       "                         'max_iter': [10000, 15000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lasso model\n",
    "lasso = Lasso()\n",
    "\n",
    "parameters = {\"max_iter\": [10000, 15000], \"alpha\": [1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20, 30, 40, 50]}\n",
    "\n",
    "lasso_regressor = GridSearchCV(lasso, parameters, scoring = \"neg_mean_squared_error\", cv = 5)\n",
    "\n",
    "lasso_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alpha', 'copy_X', 'fit_intercept', 'max_iter', 'normalize', 'positive', 'precompute', 'random_state', 'selection', 'tol', 'warm_start'])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the parameters for this model?\n",
    "lasso.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.01, 'max_iter': 10000}\n"
     ]
    }
   ],
   "source": [
    "# what's the best model given alphas?\n",
    "print(lasso_regressor.best_params_) # alpha = 0.01 and max_iter = 10000 are best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34272984504446125\n",
      "0.5191051874470141\n",
      "0.4473260686684912\n",
      "0.19117581024126473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19117581024126473"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the new model to predict\n",
    "best_lasso = lasso_regressor.best_estimator_\n",
    "\n",
    "yhat_train_lasso = best_lasso.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train, yhat_train_lasso))) # RMSE for training is .343\n",
    "print(r2_score(y_train, yhat_train_lasso)) # R squared is 51.9 percent\n",
    "\n",
    "yhat_test_lasso = best_lasso.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test, yhat_test_lasso))) # RMSE for test data is .447\n",
    "print(r2_score(y_test, yhat_test_lasso)) # R squared is 19.11 percent yikes but one percent better than ridge?\n",
    "\n",
    "# accuracy score (same as R2)\n",
    "best_lasso.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                                  l1_ratio=0.5, max_iter=1000, normalize=False,\n",
       "                                  positive=False, precompute=False,\n",
       "                                  random_state=None, selection='cyclic',\n",
       "                                  tol=0.0001, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'alpha': [1e-15, 1e-10, 1e-08, 0.0001, 0.001, 0.01, 1,\n",
       "                                   5, 10, 20, 30, 40, 50],\n",
       "                         'l1_ratio': [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1],\n",
       "                         'max_iter': [10000, 15000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build an elasticnet\n",
    "\n",
    "enet = ElasticNet()\n",
    "\n",
    "parameters = {\"alpha\": [1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20, 30, 40, 50], \"max_iter\": [10000, 15000],\n",
    "             \"l1_ratio\": [.1, .5, .7, .9, .95, .99, 1]}\n",
    "\n",
    "enet_regressor = GridSearchCV(enet, parameters, scoring = \"neg_mean_squared_error\", cv = 5)\n",
    "\n",
    "enet_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alpha', 'copy_X', 'fit_intercept', 'l1_ratio', 'max_iter', 'normalize', 'positive', 'precompute', 'random_state', 'selection', 'tol', 'warm_start'])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# elasticnet parameters\n",
    "enet.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.01, 'l1_ratio': 0.5, 'max_iter': 10000}\n"
     ]
    }
   ],
   "source": [
    "# what's the best model given alpha?\n",
    "print(enet_regressor.best_params_) # alpha = 0.01, l1_ratio = 0.5, and max_iter = 10000 are best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27946245119000845\n",
      "0.6802627973317135\n",
      "0.4685148244338771\n",
      "0.11273696320698612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11273696320698612"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the new model to predict\n",
    "best_enet = enet_regressor.best_estimator_\n",
    "\n",
    "yhat_train_enet = best_enet.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train,yhat_train_enet))) # RMSE for training is .279\n",
    "print(r2_score(y_train, yhat_train_enet)) # R squared is 68 percent\n",
    "\n",
    "yhat_test_enet = best_enet.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test, yhat_test_enet))) # RMSE for test data is .469\n",
    "print(r2_score(y_test, yhat_test_enet)) # R squared is 11.3 percent yikesssss\n",
    "\n",
    "# accuracy score (same as R2)\n",
    "best_enet.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all for penalized regression classifiers. Now on to random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Accuracy: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "#number of estimators set to length of X_test (above)\n",
    "clf = RandomForestClassifier(n_estimators=1734)\n",
    "\n",
    "#train the model using the training sets\n",
    "clf.fit(X_train,y_train.values.ravel())\n",
    "# originally had an issue with the above line - https://stackoverflow.com/questions/34165731/a-column-vector-y-was-passed-when-a-1d-array-was-expected helped\n",
    "\n",
    "yhat_train_rf = clf.predict(X_train)\n",
    "yhat_test_rf = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_train, yhat_train_rf))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, yhat_test_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some random forest interpretation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>tax</td>\n",
       "      <td>0.0289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>think</td>\n",
       "      <td>0.0177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>yes</td>\n",
       "      <td>0.0169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>rich</td>\n",
       "      <td>0.0143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>work</td>\n",
       "      <td>0.0135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>district</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>durast</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>ran</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>trial</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>residenti</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1734 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature  importance_score\n",
       "214         tax            0.0289\n",
       "59        think            0.0177\n",
       "190         yes            0.0169\n",
       "105        rich            0.0143\n",
       "242        work            0.0135\n",
       "...         ...               ...\n",
       "1112   district            0.0000\n",
       "1113     durast            0.0000\n",
       "1117        ran            0.0000\n",
       "1119      trial            0.0000\n",
       "1733  residenti            0.0000\n",
       "\n",
       "[1734 rows x 2 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = []\n",
    "scores = []\n",
    "for name, score in zip(X_train.columns,clf.feature_importances_):\n",
    "    names.append(name)\n",
    "    scores.append(np.round(score,4))\n",
    "    \n",
    "score_df = pd.DataFrame({'feature':names,'importance_score':scores})\n",
    "\n",
    "score_df.sort_values('importance_score',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 93.93939393939394\n",
      "Test set accuracy: 70.40816326530613\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(X_train,y_train)\n",
    "yhat_train_NB = Naive.predict(X_train)\n",
    "print(\"Training set accuracy:\", accuracy_score(yhat_train_NB, y_train)*100)\n",
    "yhat_test_NB = Naive.predict(X_test)\n",
    "print(\"Test set accuracy:\", accuracy_score(yhat_test_NB, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 99.13419913419914\n",
      "Test set accuracy: 71.42857142857143\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "SVM = svm.SVC(C=1.7)\n",
    "SVM.fit(X_train,y_train)\n",
    "yhat_train_SVM = SVM.predict(X_train)\n",
    "print(\"Training set accuracy:\",accuracy_score(yhat_train_SVM, y_train)*100)\n",
    "yhat_test_SVM = SVM.predict(X_test)\n",
    "print(\"Test set accuracy:\", accuracy_score(yhat_test_SVM, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They do OK. Try some ensemble techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_clf 0.70408\n",
      "svm_clf 0.69388\n",
      "knn_clf 0.63265\n",
      "nb_clf 0.70408\n",
      "voting_clf 0.7551\n"
     ]
    }
   ],
   "source": [
    "# Voting ensemble\n",
    "np.random.seed(333)\n",
    "rf_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "knn_clf = KNeighborsClassifier()\n",
    "nb_clf = naive_bayes.MultinomialNB()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "                [('rf',rf_clf),\n",
    "                ('svm',svm_clf),\n",
    "                 ('nb', nb_clf),\n",
    "                ('knn',knn_clf)],\n",
    "                voting = \"hard\")\n",
    "\n",
    "voting_clf.fit(X_train,y_train)\n",
    "\n",
    "for name,clf in ([\"rf_clf\",rf_clf],\n",
    "                 [\"svm_clf\",svm_clf],[\"knn_clf\",knn_clf], [\"nb_clf\", nb_clf],\n",
    "                 [\"voting_clf\",voting_clf]):\n",
    "    # fit the model\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    # predict\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # get acc\n",
    "    acc = sum(y_test == y_pred)/len(y_pred)\n",
    "    \n",
    "    print(name, np.round(acc,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The voting classifier can get north of 70% accuracy. Try bagging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 77.48917748917748\n",
      "Test set accuracy: 60.204081632653065\n"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(SVC(),\n",
    "                            n_estimators = 1000,\n",
    "                            max_samples = 100,\n",
    "                            bootstrap = True\n",
    "                           )\n",
    "bag_clf.fit(X_train,y_train)\n",
    "yhat_train_bag = bag_clf.predict(X_train)\n",
    "print(\"Training set accuracy:\", accuracy_score(yhat_train_bag, y_train)*100)\n",
    "yhat_test_bag = bag_clf.predict(X_test)\n",
    "print(\"Test set accuracy:\", accuracy_score(yhat_test_bag, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try boosting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 100.0\n",
      "Training set accuracy: 70.40816326530613\n"
     ]
    }
   ],
   "source": [
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                n_estimators = 1000,\n",
    "                algorithm=\"SAMME.R\",\n",
    "                learning_rate = 0.5\n",
    "            )\n",
    "ada_clf.fit(X_train, y_train)\n",
    "yhat_train_ada_clf = ada_clf.predict(X_train)\n",
    "print(\"Training set accuracy:\", accuracy_score(yhat_train_ada_clf, y_train)*100)\n",
    "yhat_test_ada_clf = ada_clf.predict(X_test)\n",
    "print(\"Test set accuracy:\", accuracy_score(yhat_test_ada_clf, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The voting classifier might work the best, but the random forest classifier doesn't do much worse, so it might be best to work with it because of the interpretability tradeoffs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 100.0\n",
      "Test set accuracy: 74.48979591836735\n"
     ]
    }
   ],
   "source": [
    "forest_clf = RandomForestClassifier(n_estimators=5000, max_features=1734, max_samples=230, random_state=333)\n",
    "forest_clf.fit(X_train,y_train)\n",
    "yhat_train_forest_clf = forest_clf.predict(X_train)\n",
    "print(\"Training set accuracy:\", accuracy_score(yhat_train_forest_clf, y_train)*100)\n",
    "yhat_test_forest_clf = forest_clf.predict(X_test)\n",
    "print(\"Test set accuracy:\", accuracy_score(yhat_test_forest_clf, y_test)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
